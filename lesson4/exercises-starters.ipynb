{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "This is the notebook containing the exercises for Feature Store, Model Monitor, and Clarify. Tested for these exercises was performed using __2 vCPU + 4 GiB notebook instance with Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized) kernel__.\n",
    "\n",
    "## Staging\n",
    "\n",
    "We'll begin by initializing some variables. These are often assumed to be present in code samples you'll find in the AWS documenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Store\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature store is a special database to give ML systems a consistent data flow across training and inference workloads. It can ingest data in batches (for training) as well as serve input features to models with very low latency for real-time prediction.\n",
    "\n",
    "For this exercise we'll work with a wine quality dataset: https://archive.ics.uci.edu/ml/datasets/wine+quality/\n",
    "\n",
    "```P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we leave the column names as-is, Feature Store won't be able to handle the `/` in `od280/od315_of_diluted_wines` (`/` is a delimiter Feature Store uses to manage how features are organized.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data, we can create a feature group. Remember to attach event time and ID columns - Feature Store needs them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='alcohol', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='malic_acid', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='alcalinity_of_ash', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='magnesium', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='total_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='flavanoids', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='nonflavanoid_phenols', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='proanthocyanins', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='color_intensity', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='hue', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='od280_od315_of_diluted_wines', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='proline', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='EventTime', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='id', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a feature group\n",
    "df[\"EventTime\"] = time.time()\n",
    "df[\"id\"] = range(len(df))\n",
    "\n",
    "# TODO: Create feature group\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name=\"wine-features\", sagemaker_session=session\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: Load Feature definitions\n",
    "feature_group.load_feature_definitions(data_frame=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature group is not created until we call the `create` method, let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceInUse",
     "evalue": "An error occurred (ResourceInUse) when calling the CreateFeatureGroup operation: Resource Already Exists: FeatureGroup with name wine-features already exists. Choose a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceInUse\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7be312c4ae1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mevent_time_feature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"EventTime\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrole_arn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0menable_online_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/feature_store/feature_group.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, s3_uri, record_identifier_name, event_time_feature_name, role_arn, online_store_kms_key_id, enable_online_store, offline_store_kms_key_id, disable_glue_table_creation, data_catalog_config, description, tags)\u001b[0m\n\u001b[1;32m    519\u001b[0m             )\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcreate_feature_store_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_feature_group\u001b[0;34m(self, feature_group_name, record_identifier_name, event_time_feature_name, feature_definitions, role_arn, online_store_config, offline_store_config, description, tags)\u001b[0m\n\u001b[1;32m   4004\u001b[0m             \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4005\u001b[0m         )\n\u001b[0;32m-> 4006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4008\u001b[0m     def describe_feature_group(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceInUse\u001b[0m: An error occurred (ResourceInUse) when calling the CreateFeatureGroup operation: Resource Already Exists: FeatureGroup with name wine-features already exists. Choose a different name."
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/features\",\n",
    "    record_identifier_name='id',\n",
    "    event_time_feature_name=\"EventTime\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, ingest some data into your feature group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='wine-features', sagemaker_fs_runtime_client_config=<botocore.config.Config object at 0x7fbb3dfc3160>, max_workers=3, max_processes=1, profile_name=None, _async_result=<multiprocess.pool.MapResult object at 0x7fbb3de4cdd8>, _processing_pool=<pool ProcessPool(ncpus=1)>, _failed_indices=[])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "feature_group.ingest(data_frame=df, max_workers=3, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You've demonstrated your understanding of creating feature groups and ingesting data into them using Feature Store. Next up we'll cover Model Monitor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll create a monitoring schedule for a deployed model. We're going to provide code to help you deploy a model and get started, so that you can focus on Model Monitor for this exercise. __Remember to clean up your model before you end a work session__. We'll provide some code at the end to help you clean up your model. We'll begin by reloading our data from the previous exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-14 14:15:49 Starting - Starting the training job...\n",
      "2022-01-14 14:16:13 Starting - Launching requested ML instancesProfilerReport-1642169749: InProgress\n",
      "......\n",
      "2022-01-14 14:17:13 Starting - Preparing the instances for training.........\n",
      "2022-01-14 14:18:48 Downloading - Downloading input data...\n",
      "2022-01-14 14:19:14 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-01-14:14:19:23:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-01-14:14:19:23:INFO] File size need to be processed in the node: 0.01mb. Available memory size in the node: 8343.7mb\u001b[0m\n",
      "\u001b[34m[2022-01-14:14:19:23:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:19:23] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:19:23] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-01-14:14:19:23:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:19:23] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:19:23] 89x13 matrix with 1157 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.759657#011validation-rmse:0.685354\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.616137#011validation-rmse:0.821641\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.501087#011validation-rmse:0.858446\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.430041#011validation-rmse:0.925116\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.377443#011validation-rmse:0.979923\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 4 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.337549#011validation-rmse:1.0265\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.309158#011validation-rmse:1.06425\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 8 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.287472#011validation-rmse:1.09787\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.273879#011validation-rmse:1.12296\u001b[0m\n",
      "\u001b[34m[14:19:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 6 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.264732#011validation-rmse:1.1432\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.9357#011validation-rmse:0.53422\u001b[0m\n",
      "\n",
      "2022-01-14 14:19:39 Uploading - Uploading generated training model\n",
      "2022-01-14 14:19:39 Completed - Training job completed\n",
      "Training seconds: 51\n",
      "Billable seconds: 51\n"
     ]
    }
   ],
   "source": [
    "algo_image = sagemaker.image_uris.retrieve(\"xgboost\", region, version='latest')\n",
    "s3_output_location = f\"s3://{bucket}/models/wine_model\"\n",
    "\n",
    "model=sagemaker.estimator.Estimator(\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "model.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)\n",
    "\n",
    "\n",
    "model.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your training job has finished, you can perform the first task in this exercise: creating a data capture config. Configure your model to sample `34%` of inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "capture_uri = f's3://{bucket}/data-capture'\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=capture_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We'll use your config to deploy a model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You should see an indicator like this when the deployment finishes:\n",
    "\n",
    "```\n",
    "-----------------!\n",
    "```\n",
    "We can test your deployment like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6030303239822388,0.6030303239822388,0.6030303239822388,0.6030303239822388,0.6030303239822388'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "inputs = test.copy()\n",
    "# Drop the target variable\n",
    "inputs = inputs.drop(columns=inputs.columns[0])\n",
    "x_pred = xgb_predictor.predict(inputs.sample(5).values).decode('utf-8')\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All systems go! To finish up the exercise, we're going to provide you with a DefaultModelMonitor and a suggested baseline. Combine the `xgb_predictor` and the provided `my_monitor` to configure the monitoring schedule for _hourly_ monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2022-01-14-12-53-12-764\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-934110659707/data/train.csv', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-934110659707/model-monitor/baselining/baseline-suggestion-job-2022-01-14-12-53-12-764/results', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".............................\u001b[34m2022-01-14 12:57:46,014 - matplotlib.font_manager - INFO - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:46.572960: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:46.572991: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:48.142014: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:48.142044: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:48.142069: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-2-73-154.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:48.142333: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,708 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:934110659707:processing-job/baseline-suggestion-job-2022-01-14-12-53-12-764', 'ProcessingJobName': 'baseline-suggestion-job-2022-01-14-12-53-12-764', 'Environment': {'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-934110659707/data/train.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://sagemaker-us-east-1-934110659707/model-monitor/baselining/baseline-suggestion-job-2022-01-14-12-53-12-764/results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::934110659707:role/service-role/AmazonSageMaker-ExecutionRole-20220111T121707', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,708 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,708 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": false, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,708 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,709 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,766 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,767 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,767 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,775 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,775 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:49,775 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,263 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.2.73.154\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn\u001b[0m\n",
      "\u001b[34m-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_312\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,270 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,274 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-b047e0fd-f2ae-4552-9ad9-255a833ee55a\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,801 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,816 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,817 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,819 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,825 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,825 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,825 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,825 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,867 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,884 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,884 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,889 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,889 INFO blockmanagement.BlockManager: The block deletion will start around 2022 Jan 14 12:57:50\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,891 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,891 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,893 INFO util.GSet: 2.0% max memory 3.1 GB = 63.3 MB\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,893 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,989 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,993 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,993 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,993 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,993 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,993 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,993 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,993 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,994 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,994 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,994 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:50,994 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,019 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,019 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,019 INFO util.GSet: 1.0% max memory 3.1 GB = 31.7 MB\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,019 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,021 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,021 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,021 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,021 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,026 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,029 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,029 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,029 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,029 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,035 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,035 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,035 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,038 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,038 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,040 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,040 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,040 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 972.7 KB\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,040 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,062 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1775266937-10.2.73.154-1642165071055\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,075 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,083 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,163 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 386 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,174 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,177 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.2.73.154\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:51,187 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:53,246 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:53,247 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:55,321 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:55,322 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:57,389 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:57,390 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:59,478 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:57:59,479 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:01,604 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:01,605 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:11,615 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:12 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:12 INFO  Main:28 - Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:12 INFO  Main:31 - Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:12 INFO  FileUtil:66 - Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SparkContext:54 - Running Spark version 2.3.1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SparkContext:54 - Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35761.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SparkEnv:54 - Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SparkEnv:54 - Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-9e80df7c-2807-4fe5-867d-b8fb2f9f9c85\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  MemoryStore:54 - MemoryStore started with capacity 1458.6 MB\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SparkEnv:54 - Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:13 INFO  SparkContext:54 - Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.2.73.154:35761/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1642165093685\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  RMProxy:133 - Connecting to ResourceManager at /10.2.73.154:8032\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  Client:54 - Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  Configuration:2636 - resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  ResourceUtils:427 - Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (15743 MB per container)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  Client:54 - Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  Client:54 - Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:14 INFO  Client:54 - Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:15 WARN  Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:17 INFO  Client:54 - Uploading resource file:/tmp/spark-4ead64d5-a221-43c8-b0a4-efd0d03d9f33/__spark_libs__8535629054697589261.zip -> hdfs://10.2.73.154/user/root/.sparkStaging/application_1642165076866_0001/__spark_libs__8535629054697589261.zip\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:18 INFO  Client:54 - Uploading resource file:/tmp/spark-4ead64d5-a221-43c8-b0a4-efd0d03d9f33/__spark_conf__6711177501332458552.zip -> hdfs://10.2.73.154/user/root/.sparkStaging/application_1642165076866_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:18 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:18 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:18 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:18 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:18 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:18 INFO  Client:54 - Submitting application application_1642165076866_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:19 INFO  YarnClientImpl:310 - Submitted application application_1642165076866_0001\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:19 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1642165076866_0001 and attemptId None\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:20 INFO  Client:54 - Application report for application_1642165076866_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:20 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Fri Jan 14 12:58:19 +0000 2022] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1642165098965\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1642165076866_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:21 INFO  Client:54 - Application report for application_1642165076866_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:22 INFO  Client:54 - Application report for application_1642165076866_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:23 INFO  Client:54 - Application report for application_1642165076866_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:24 INFO  Client:54 - Application report for application_1642165076866_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:24 INFO  YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1642165076866_0001), /proxy/application_1642165076866_0001\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:24 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  Client:54 - Application report for application_1642165076866_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.2.73.154\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: 0\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1642165098965\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1642165076866_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  YarnClientSchedulerBackend:54 - Application application_1642165076866_0001 has started running.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38609.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  NettyBlockTransferService:54 - Server created on 10.2.73.154:38609\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.2.73.154, 38609, None)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.2.73.154:38609 with 1458.6 MB RAM, BlockManagerId(driver, 10.2.73.154, 38609, None)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.2.73.154, 38609, None)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.2.73.154, 38609, None)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:25 INFO  log:192 - Logging initialized @13422ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:26 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.2.73.154:36836) with ID 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:27 INFO  BlockManagerMasterEndpoint:54 - Registering block manager algo-1:40899 with 5.8 GB RAM, BlockManagerId(1, algo-1, 40899, None)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:43 INFO  YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:43 WARN  SparkContext:66 - Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:44 INFO  DatasetReader:125 - Files to process:List(file:///opt/ml/processing/input/baseline_dataset_input/train.csv)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:44 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/spark-2.3.1/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:44 INFO  SharedState:54 - Warehouse path is 'file:/usr/spark-2.3.1/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:44 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:45 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:45 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#0, None)) > 0)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:45 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:45 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:45 INFO  CodeGenerator:54 - Code generated in 180.019494 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:45 INFO  CodeGenerator:54 - Code generated in 29.719244 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:45 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 429.7 KB, free 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.2.73.154:38609 (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  SparkContext:54 - Created broadcast 0 from csv at DatasetReader.scala:76\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  SparkContext:54 - Starting job: csv at DatasetReader.scala:76\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  DAGScheduler:54 - Got job 0 (csv at DatasetReader.scala:76) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at DatasetReader.scala:76)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:76), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.4 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.2.73.154:38609 (size: 4.5 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at DatasetReader.scala:76) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  YarnScheduler:54 - Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:47 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on algo-1:40899 (size: 4.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:47 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on algo-1:40899 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 1965 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  DAGScheduler:54 - ResultStage 0 (csv at DatasetReader.scala:76) finished in 2.050 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  DAGScheduler:54 - Job 0 finished: csv at DatasetReader.scala:76, took 2.106427 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  CodeGenerator:54 - Code generated in 8.577524 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 429.7 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.2.73.154:38609 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  SparkContext:54 - Created broadcast 2 from csv at DatasetReader.scala:76\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceStrategy:54 - Output Data Schema: struct<_c0: string, _c1: string, _c2: string, _c3: string, _c4: string ... 12 more fields>\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 429.7 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.2.73.154:38609 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  SparkContext:54 - Created broadcast 3 from cache at DataAnalyzer.scala:78\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  CodeGenerator:54 - Code generated in 31.069071 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  CodeGenerator:54 - Code generated in 25.559949 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  SparkContext:54 - Starting job: head at DataAnalyzer.scala:81\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  DAGScheduler:54 - Got job 1 (head at DataAnalyzer.scala:81) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (head at DataAnalyzer.scala:81)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[17] at head at DataAnalyzer.scala:81), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 29.1 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.5 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.2.73.154:38609 (size: 11.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[17] at head at DataAnalyzer.scala:81) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  YarnScheduler:54 - Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on algo-1:40899 (size: 11.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on algo-1:40899 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:48 INFO  BlockManagerInfo:54 - Added rdd_11_0 in memory on algo-1:40899 (size: 10.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 426 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  YarnScheduler:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - ResultStage 1 (head at DataAnalyzer.scala:81) finished in 0.469 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - Job 1 finished: head at DataAnalyzer.scala:81, took 0.474963 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DataAnalyzer:89 - The number of columns in the dataframe is 14\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DataAnalyzer:116 - Number of shards is: 3\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  CodeGenerator:54 - Code generated in 18.111863 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - Registering RDD 22 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - Got job 2 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 70.9 KB, free 1457.1 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 25.3 KB, free 1457.1 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.2.73.154:38609 (size: 25.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  YarnScheduler:54 - Adding task set 2.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:49 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on algo-1:40899 (size: 25.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 897 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  YarnScheduler:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - ShuffleMapStage 2 (collect at AnalysisRunner.scala:313) finished in 0.917 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[25] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 83.1 KB, free 1457.0 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.4 KB, free 1457.0 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.2.73.154:38609 (size: 28.4 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[25] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  YarnScheduler:54 - Adding task set 3.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on algo-1:40899 (size: 28.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 310 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - ResultStage 3 (collect at AnalysisRunner.scala:313) finished in 0.353 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  YarnScheduler:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  DAGScheduler:54 - Job 2 finished: collect at AnalysisRunner.scala:313, took 1.290250 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:50 INFO  CodeGenerator:54 - Code generated in 21.213854 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Got job 3 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[34] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 30.9 KB, free 1456.9 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.0 KB, free 1456.9 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.2.73.154:38609 (size: 13.0 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[34] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  YarnScheduler:54 - Adding task set 4.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on algo-1:40899 (size: 13.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 168 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - ResultStage 4 (treeReduce at KLLRunner.scala:107) finished in 0.180 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Job 3 finished: treeReduce at KLLRunner.scala:107, took 0.186845 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  YarnScheduler:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  CodeGenerator:54 - Code generated in 67.40077 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  CodeGenerator:54 - Code generated in 103.866596 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  CodeGenerator:54 - Code generated in 60.740383 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Registering RDD 39 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Got job 4 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 5)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 5 (MapPartitionsRDD[39] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 69.5 KB, free 1456.9 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.0 KB, free 1456.8 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.2.73.154:38609 (size: 24.0 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[39] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  YarnScheduler:54 - Adding task set 5.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:51 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on algo-1:40899 (size: 24.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 380 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  YarnScheduler:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - ShuffleMapStage 5 (collect at AnalysisRunner.scala:313) finished in 0.397 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - waiting: Set(ResultStage 6)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 54.0 KB, free 1456.8 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 16.5 KB, free 1456.8 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.2.73.154:38609 (size: 16.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  YarnScheduler:54 - Adding task set 6.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on algo-1:40899 (size: 16.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 123 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  YarnScheduler:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - ResultStage 6 (collect at AnalysisRunner.scala:313) finished in 0.144 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Job 4 finished: collect at AnalysisRunner.scala:313, took 0.545672 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Registering RDD 49 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Got job 5 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 7 (MapPartitionsRDD[49] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 25.6 KB, free 1456.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 11.8 KB, free 1456.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 10.2.73.154:38609 (size: 11.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[49] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  YarnScheduler:54 - Adding task set 7.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:52 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on algo-1:40899 (size: 11.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 1018 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  YarnScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - ShuffleMapStage 7 (countByKey at ColumnProfiler.scala:566) finished in 1.050 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - waiting: Set(ResultStage 8)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Submitting ResultStage 8 (ShuffledRDD[50] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.2 KB, free 1456.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1456.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 10.2.73.154:38609 (size: 1924.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 8 (ShuffledRDD[50] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  YarnScheduler:54 - Adding task set 8.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 8, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on algo-1:40899 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 2 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 8) in 78 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  YarnScheduler:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - ResultStage 8 (countByKey at ColumnProfiler.scala:566) finished in 0.096 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Job 5 finished: countByKey at ColumnProfiler.scala:566, took 1.184354 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 80\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 211\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 97\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 274\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on algo-1:40899 in memory (size: 4.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 10.2.73.154:38609 in memory (size: 4.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 256\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 53\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 196\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 233\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 237\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 16\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 261\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 2\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 149\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 150\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 208\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 180\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 222\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 45\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 135\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned shuffle 2\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 10.2.73.154:38609 in memory (size: 24.0 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on algo-1:40899 in memory (size: 24.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 77\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 195\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 240\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 23\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 101\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 141\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 133\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 253\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 96\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 114\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 177\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 267\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 153\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 198\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 128\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 75\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 25\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 174\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 236\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 262\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 61\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 46\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 102\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 214\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 246\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 275\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 0\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 66\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 268\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 108\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 242\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 26\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 258\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 42\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 172\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on 10.2.73.154:38609 in memory (size: 38.3 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on algo-1:40899 in memory (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 181\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 219\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 4\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 27\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 131\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 248\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 206\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 11\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 254\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 115\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 95\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 103\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 263\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 176\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 10.2.73.154:38609 in memory (size: 11.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on algo-1:40899 in memory (size: 11.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 127\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 160\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 110\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 73\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 67\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 126\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 165\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 175\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 87\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 134\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 136\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 7\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 48\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 70\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 120\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 209\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 235\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 76\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned shuffle 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 31\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 52\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 122\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 88\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 179\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 225\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 212\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 243\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 264\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 34\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 207\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 117\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 10.2.73.154:38609 in memory (size: 13.0 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on algo-1:40899 in memory (size: 13.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 139\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 184\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 30\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 194\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 247\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 244\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 272\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 143\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 24\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 85\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 223\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 118\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 146\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 10.2.73.154:38609 in memory (size: 16.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on algo-1:40899 in memory (size: 16.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 151\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 8\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 49\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 205\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 69\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 163\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 113\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 123\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 105\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 9\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 47\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 252\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 277\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 170\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 203\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 241\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 278\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 10.2.73.154:38609 in memory (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 189\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Registering RDD 55 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Got job 6 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Final stage: ResultStage 10 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 9)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 9 (MapPartitionsRDD[55] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned shuffle 0\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 156\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 140\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 59\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 255\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 14\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 193\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 201\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 132\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 167\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 158\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 99\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 269\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 215\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 100\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 86\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 260\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 70.9 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 10.2.73.154:38609 in memory (size: 28.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on algo-1:40899 in memory (size: 28.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.5 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 162\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 270\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 266\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 50\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 173\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 55\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 1\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 232\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 226\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on 10.2.73.154:38609 (size: 25.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 10.2.73.154:38609 in memory (size: 11.5 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  SparkContext:54 - Created broadcast 12 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[55] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  YarnScheduler:54 - Adding task set 9.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 9, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on algo-1:40899 in memory (size: 11.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 5\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 18\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 166\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 218\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 220\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 71\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 234\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 20\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 121\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 187\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 204\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 210\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 186\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 19\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 161\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 35\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 250\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 119\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 171\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 271\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 152\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 125\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 130\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 231\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 54\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 183\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 109\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 188\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 155\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 157\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 145\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 28\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 92\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 63\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 74\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 230\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 259\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 147\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 91\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 273\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 142\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 216\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 32\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 84\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 21\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 89\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 62\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 199\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 107\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 51\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 94\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 15\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 98\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 6\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 217\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 12\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 191\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 249\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 124\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 227\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 229\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 13\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 197\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 104\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 192\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 276\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 72\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 185\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 221\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 213\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 257\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 44\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 79\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 144\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 164\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 57\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 56\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 138\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 90\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 33\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 159\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 116\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 68\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 78\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 182\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 60\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 22\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 239\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 111\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 200\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 129\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 245\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 3\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 178\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 112\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 10.2.73.154:38609 in memory (size: 25.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on algo-1:40899 in memory (size: 25.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on algo-1:40899 (size: 25.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 10\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 58\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 106\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 17\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 10.2.73.154:38609 in memory (size: 1924.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on algo-1:40899 in memory (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 265\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 65\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 224\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 81\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 137\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 169\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 29\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 64\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 190\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 83\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 168\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 238\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 43\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 148\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 228\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 251\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 93\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 202\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 154\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:53 INFO  ContextCleaner:54 - Cleaned accumulator 82\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 9) in 222 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - ShuffleMapStage 9 (collect at AnalysisRunner.scala:313) finished in 0.239 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - waiting: Set(ResultStage 10)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting ResultStage 10 (MapPartitionsRDD[58] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 83.1 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 28.4 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on 10.2.73.154:38609 (size: 28.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Created broadcast 13 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[58] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Adding task set 10.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 10.0 (TID 10, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on algo-1:40899 (size: 28.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 3 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 10.0 (TID 10) in 100 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - ResultStage 10 (collect at AnalysisRunner.scala:313) finished in 0.112 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Job 6 finished: collect at AnalysisRunner.scala:313, took 0.356807 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  CodeGenerator:54 - Code generated in 11.992901 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Got job 7 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting ResultStage 11 (MapPartitionsRDD[67] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 30.8 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 12.9 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on 10.2.73.154:38609 (size: 12.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[67] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Adding task set 11.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 11, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on algo-1:40899 (size: 12.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 11) in 58 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - ResultStage 11 (treeReduce at KLLRunner.scala:107) finished in 0.067 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Job 7 finished: treeReduce at KLLRunner.scala:107, took 0.070603 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  CodeGenerator:54 - Code generated in 53.315363 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  CodeGenerator:54 - Code generated in 42.32304 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Registering RDD 72 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Got job 8 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 12)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 12 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 69.0 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.7 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on 10.2.73.154:38609 (size: 23.7 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Created broadcast 15 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[72] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Adding task set 12.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 12.0 (TID 12, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on algo-1:40899 (size: 23.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 12.0 (TID 12) in 85 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - ShuffleMapStage 12 (collect at AnalysisRunner.scala:313) finished in 0.096 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - waiting: Set(ResultStage 13)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[75] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 53.8 KB, free 1457.8 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 16.2 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on 10.2.73.154:38609 (size: 16.2 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Created broadcast 16 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[75] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Adding task set 13.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 13, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on algo-1:40899 (size: 16.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 4 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 13) in 85 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - ResultStage 13 (collect at AnalysisRunner.scala:313) finished in 0.097 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Job 8 finished: collect at AnalysisRunner.scala:313, took 0.201049 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Registering RDD 82 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Got job 9 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Final stage: ResultStage 15 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 14 (MapPartitionsRDD[82] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 25.6 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 11.8 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on 10.2.73.154:38609 (size: 11.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Created broadcast 17 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[82] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Adding task set 14.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 14.0 (TID 14, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on algo-1:40899 (size: 11.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  TaskSetManager:54 - Finished task 0.0 in stage 14.0 (TID 14) in 68 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  YarnScheduler:54 - Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - ShuffleMapStage 14 (countByKey at ColumnProfiler.scala:566) finished in 0.081 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - waiting: Set(ResultStage 15)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  DAGScheduler:54 - Submitting ResultStage 15 (ShuffledRDD[83] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 3.2 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 1922.0 B, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on 10.2.73.154:38609 (size: 1922.0 B, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:54 INFO  SparkContext:54 - Created broadcast 18 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 15 (ShuffledRDD[83] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  YarnScheduler:54 - Adding task set 15.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 15.0 (TID 15, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on algo-1:40899 (size: 1922.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 5 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 15.0 (TID 15) in 57 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  YarnScheduler:54 - Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - ResultStage 15 (countByKey at ColumnProfiler.scala:566) finished in 0.074 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Job 9 finished: countByKey at ColumnProfiler.scala:566, took 0.168068 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  CodeGenerator:54 - Code generated in 9.826803 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Registering RDD 88 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Got job 10 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Final stage: ResultStage 17 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 16)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 16 (MapPartitionsRDD[88] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 62.5 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 22.2 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on 10.2.73.154:38609 (size: 22.2 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  SparkContext:54 - Created broadcast 19 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[88] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  YarnScheduler:54 - Adding task set 16.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 16.0 (TID 16, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on algo-1:40899 (size: 22.2 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 16.0 (TID 16) in 200 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  YarnScheduler:54 - Removed TaskSet 16.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - ShuffleMapStage 16 (collect at AnalysisRunner.scala:313) finished in 0.210 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - waiting: Set(ResultStage 17)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Submitting ResultStage 17 (MapPartitionsRDD[91] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 72.7 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.6 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on 10.2.73.154:38609 (size: 25.6 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  SparkContext:54 - Created broadcast 20 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[91] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  YarnScheduler:54 - Adding task set 17.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 17.0 (TID 17, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on algo-1:40899 (size: 25.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 6 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 17.0 (TID 17) in 186 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  YarnScheduler:54 - Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - ResultStage 17 (collect at AnalysisRunner.scala:313) finished in 0.198 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Job 10 finished: collect at AnalysisRunner.scala:313, took 0.414656 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  CodeGenerator:54 - Code generated in 12.200445 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  SparkContext:54 - Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Got job 11 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Final stage: ResultStage 18 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Submitting ResultStage 18 (MapPartitionsRDD[100] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 30.3 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 12.8 KB, free 1457.5 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on 10.2.73.154:38609 (size: 12.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  SparkContext:54 - Created broadcast 21 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[100] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  YarnScheduler:54 - Adding task set 18.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 18.0 (TID 18, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8340 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on algo-1:40899 (size: 12.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 18.0 (TID 18) in 86 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  YarnScheduler:54 - Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - ResultStage 18 (treeReduce at KLLRunner.scala:107) finished in 0.095 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  DAGScheduler:54 - Job 11 finished: treeReduce at KLLRunner.scala:107, took 0.100841 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  CodeGenerator:54 - Code generated in 21.185908 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:55 INFO  CodeGenerator:54 - Code generated in 31.205385 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  CodeGenerator:54 - Code generated in 27.273081 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Registering RDD 105 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Got job 12 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Final stage: ResultStage 20 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 19 (MapPartitionsRDD[105] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 60.4 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 21.5 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on 10.2.73.154:38609 (size: 21.5 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Created broadcast 22 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[105] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Adding task set 19.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 19.0 (TID 19, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on algo-1:40899 (size: 21.5 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 19.0 (TID 19) in 69 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - ShuffleMapStage 19 (collect at AnalysisRunner.scala:313) finished in 0.080 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - waiting: Set(ResultStage 20)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting ResultStage 20 (MapPartitionsRDD[108] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 44.4 KB, free 1457.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 13.8 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on 10.2.73.154:38609 (size: 13.8 KB, free: 1458.4 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Created broadcast 23 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[108] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Adding task set 20.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 20.0 (TID 20, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on algo-1:40899 (size: 13.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 7 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 20.0 (TID 20) in 75 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - ResultStage 20 (collect at AnalysisRunner.scala:313) finished in 0.086 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Job 12 finished: collect at AnalysisRunner.scala:313, took 0.171697 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Registering RDD 115 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Got job 13 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Final stage: ResultStage 22 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 21 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_24 stored as values in memory (estimated size 25.7 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.8 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on 10.2.73.154:38609 (size: 11.8 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Created broadcast 24 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[115] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Adding task set 21.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 21.0 (TID 21, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_24_piece0 in memory on algo-1:40899 (size: 11.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 21.0 (TID 21) in 105 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Removed TaskSet 21.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - ShuffleMapStage 21 (countByKey at ColumnProfiler.scala:566) finished in 0.127 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - waiting: Set(ResultStage 22)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting ResultStage 22 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_25 stored as values in memory (estimated size 3.2 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 1924.0 B, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on 10.2.73.154:38609 (size: 1924.0 B, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Created broadcast 25 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 22 (ShuffledRDD[116] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Adding task set 22.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 22.0 (TID 22, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_25_piece0 in memory on algo-1:40899 (size: 1924.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 8 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 22.0 (TID 22) in 61 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - ResultStage 22 (countByKey at ColumnProfiler.scala:566) finished in 0.076 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Job 13 finished: countByKey at ColumnProfiler.scala:566, took 0.211354 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  ConstraintGenerator:45 - Generating Constraints:\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  ConstraintGenerator:50 - Constraints: {\n",
      "  \"version\" : 0.0,\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"_c0\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c3\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c4\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c5\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c6\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c7\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c8\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c9\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c10\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c11\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c12\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c13\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"num_constraints\" : {\n",
      "      \"is_non_negative\" : true\n",
      "    }\n",
      "  } ],\n",
      "  \"monitoring_config\" : {\n",
      "    \"evaluate_constraints\" : \"Enabled\",\n",
      "    \"emit_metrics\" : \"Enabled\",\n",
      "    \"datatype_check_threshold\" : 1.0,\n",
      "    \"domain_content_threshold\" : 1.0,\n",
      "    \"distribution_constraints\" : {\n",
      "      \"perform_comparison\" : \"Enabled\",\n",
      "      \"comparison_threshold\" : 0.1,\n",
      "      \"comparison_method\" : \"Robust\"\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  FileUtil:29 - Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  StatsGenerator:65 - Generating Stats:\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  CodeGenerator:54 - Code generated in 15.432465 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  CodeGenerator:54 - Code generated in 8.339621 ms\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Starting job: count at StatsGenerator.scala:67\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Registering RDD 121 (count at StatsGenerator.scala:67)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Got job 14 (count at StatsGenerator.scala:67) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Final stage: ResultStage 24 (count at StatsGenerator.scala:67)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 23)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 23 (MapPartitionsRDD[121] at count at StatsGenerator.scala:67), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_26 stored as values in memory (estimated size 26.4 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 11.6 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on 10.2.73.154:38609 (size: 11.6 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Created broadcast 26 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[121] at count at StatsGenerator.scala:67) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Adding task set 23.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 23.0 (TID 23, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8329 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_26_piece0 in memory on algo-1:40899 (size: 11.6 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 23.0 (TID 23) in 72 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - ShuffleMapStage 23 (count at StatsGenerator.scala:67) finished in 0.085 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - waiting: Set(ResultStage 24)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting ResultStage 24 (MapPartitionsRDD[124] at count at StatsGenerator.scala:67), which has no missing parents\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_27 stored as values in memory (estimated size 7.4 KB, free 1457.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MemoryStore:54 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1457.2 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on 10.2.73.154:38609 (size: 3.8 KB, free: 1458.3 MB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  SparkContext:54 - Created broadcast 27 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[124] at count at StatsGenerator.scala:67) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Adding task set 24.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 24.0 (TID 24, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  BlockManagerInfo:54 - Added broadcast_27_piece0 in memory on algo-1:40899 (size: 3.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 9 to 10.2.73.154:36836\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 24.0 (TID 24) in 94 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  YarnScheduler:54 - Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - ResultStage 24 (count at StatsGenerator.scala:67) finished in 0.114 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:56 INFO  DAGScheduler:54 - Job 14 finished: count at StatsGenerator.scala:67, took 0.206031 s\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  StatsGenerator:70 - Stats: {\n",
      "  \"version\" : 0.0,\n",
      "  \"dataset\" : {\n",
      "    \"item_count\" : 89\n",
      "  },\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"_c0\",\n",
      "    \"inferred_type\" : \"Integral\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.5393258426966292,\n",
      "      \"sum\" : 137.0,\n",
      "      \"std_dev\" : 0.49845107893974944,\n",
      "      \"min\" : 1.0,\n",
      "      \"max\" : 2.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.0,\n",
      "            \"upper_bound\" : 1.1,\n",
      "            \"count\" : 41.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.1,\n",
      "            \"upper_bound\" : 1.2,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.2,\n",
      "            \"upper_bound\" : 1.3,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.3,\n",
      "            \"upper_bound\" : 1.4,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.4,\n",
      "            \"upper_bound\" : 1.5,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.5,\n",
      "            \"upper_bound\" : 1.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.6,\n",
      "            \"upper_bound\" : 1.7,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.7,\n",
      "            \"upper_bound\" : 1.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.8,\n",
      "            \"upper_bound\" : 1.9,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.9,\n",
      "            \"upper_bound\" : 2.0,\n",
      "            \"count\" : 48.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c1\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 12.6770786516854,\n",
      "      \"sum\" : 1128.2600000000007,\n",
      "      \"std_dev\" : 0.7047275387880579,\n",
      "      \"min\" : 11.03,\n",
      "      \"max\" : 14.34,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 11.03,\n",
      "            \"upper_bound\" : 11.360999999999999,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.360999999999999,\n",
      "            \"upper_bound\" : 11.692,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.692,\n",
      "            \"upper_bound\" : 12.023,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 12.023,\n",
      "            \"upper_bound\" : 12.354,\n",
      "            \"count\" : 15.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 12.354,\n",
      "            \"upper_bound\" : 12.685,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 12.685,\n",
      "            \"upper_bound\" : 13.016,\n",
      "            \"count\" : 15.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 13.016,\n",
      "            \"upper_bound\" : 13.347,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 13.347,\n",
      "            \"upper_bound\" : 13.678,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 13.678,\n",
      "            \"upper_bound\" : 14.009,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 14.009,\n",
      "            \"upper_bound\" : 14.34,\n",
      "            \"count\" : 3.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 12.08, 12.08, 12.0, 12.69, 12.29, 11.62, 12.47, 11.81, 12.29, 12.37, 12.29, 12.08, 12.6, 12.34, 11.82, 12.51, 12.42, 12.25, 12.72, 12.22, 11.61, 11.46, 12.52, 11.76, 11.41, 12.08, 11.03, 11.82, 12.42, 12.77, 12.0, 11.45, 11.56, 12.42, 13.05, 11.87, 12.07, 12.43, 11.79, 12.37, 12.04, 12.86, 12.88, 12.81, 12.7, 12.51, 12.6, 12.25, 12.53, 13.49, 12.84, 12.93, 13.36, 13.52, 13.62, 12.25, 13.16, 13.88, 12.87, 13.32, 13.08, 13.5, 12.79, 13.11, 13.23, 12.58, 13.17, 13.84, 12.45, 14.34, 13.48, 12.36, 13.69, 12.85, 12.96, 13.78, 13.73, 13.45, 12.82, 13.58, 13.4, 12.2, 12.77, 14.16, 13.71, 13.4, 13.27, 13.17, 14.13 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c2\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2.825730337078651,\n",
      "      \"sum\" : 251.48999999999992,\n",
      "      \"std_dev\" : 1.2033482199753587,\n",
      "      \"min\" : 0.74,\n",
      "      \"max\" : 5.8,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.74,\n",
      "            \"upper_bound\" : 1.246,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.246,\n",
      "            \"upper_bound\" : 1.752,\n",
      "            \"count\" : 22.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.752,\n",
      "            \"upper_bound\" : 2.258,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.258,\n",
      "            \"upper_bound\" : 2.7640000000000002,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.7640000000000002,\n",
      "            \"upper_bound\" : 3.2699999999999996,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.2699999999999996,\n",
      "            \"upper_bound\" : 3.776,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.776,\n",
      "            \"upper_bound\" : 4.281999999999999,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.281999999999999,\n",
      "            \"upper_bound\" : 4.788,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.788,\n",
      "            \"upper_bound\" : 5.2940000000000005,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.2940000000000005,\n",
      "            \"upper_bound\" : 5.8,\n",
      "            \"count\" : 3.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.33, 1.83, 1.51, 1.53, 2.83, 1.99, 1.52, 2.12, 1.41, 1.07, 3.17, 2.08, 1.34, 2.45, 1.72, 1.73, 2.55, 1.73, 1.75, 1.29, 1.35, 3.74, 2.43, 2.68, 0.74, 1.39, 1.51, 1.47, 1.61, 3.43, 3.43, 2.4, 2.05, 4.43, 5.8, 4.31, 2.16, 1.53, 2.13, 1.63, 4.3, 1.35, 2.99, 2.31, 3.55, 1.24, 2.46, 4.72, 5.51, 3.59, 2.96, 2.81, 2.56, 3.17, 4.95, 3.88, 3.57, 5.04, 4.61, 3.24, 3.9, 3.12, 2.67, 1.9, 3.3, 1.29, 5.19, 4.12, 3.03, 1.68, 1.67, 3.83, 3.26, 3.27, 3.45, 2.76, 4.36, 3.7, 3.37, 2.58, 4.6, 3.03, 2.39, 2.51, 5.65, 3.91, 4.28, 2.59, 4.1 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c3\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2.3632584269662913,\n",
      "      \"sum\" : 210.32999999999993,\n",
      "      \"std_dev\" : 0.26075420119381026,\n",
      "      \"min\" : 1.7,\n",
      "      \"max\" : 3.23,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.7,\n",
      "            \"upper_bound\" : 1.853,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.853,\n",
      "            \"upper_bound\" : 2.006,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.006,\n",
      "            \"upper_bound\" : 2.159,\n",
      "            \"count\" : 5.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.159,\n",
      "            \"upper_bound\" : 2.312,\n",
      "            \"count\" : 25.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.312,\n",
      "            \"upper_bound\" : 2.465,\n",
      "            \"count\" : 21.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.465,\n",
      "            \"upper_bound\" : 2.618,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.618,\n",
      "            \"upper_bound\" : 2.771,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.771,\n",
      "            \"upper_bound\" : 2.924,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.924,\n",
      "            \"upper_bound\" : 3.077,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.077,\n",
      "            \"upper_bound\" : 3.23,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 2.3, 2.32, 2.42, 2.26, 2.22, 2.28, 2.2, 2.74, 1.98, 2.1, 2.21, 1.7, 1.9, 2.46, 1.88, 1.98, 2.27, 2.12, 2.28, 1.94, 2.7, 1.82, 2.17, 2.92, 2.5, 2.5, 2.2, 1.99, 2.19, 1.98, 2.0, 2.42, 3.23, 2.73, 2.13, 2.39, 2.17, 2.29, 2.78, 2.3, 2.38, 2.32, 2.4, 2.4, 2.36, 2.25, 2.2, 2.54, 2.64, 2.19, 2.61, 2.7, 2.35, 2.72, 2.35, 2.2, 2.15, 2.23, 2.48, 2.38, 2.36, 2.62, 2.48, 2.75, 2.28, 2.1, 2.32, 2.38, 2.64, 2.7, 2.64, 2.38, 2.54, 2.58, 2.35, 2.3, 2.26, 2.6, 2.3, 2.69, 2.86, 2.32, 2.28, 2.48, 2.45, 2.48, 2.26, 2.37, 2.74 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c4\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 21.124719101123596,\n",
      "      \"sum\" : 1880.1,\n",
      "      \"std_dev\" : 2.4881869622876147,\n",
      "      \"min\" : 16.0,\n",
      "      \"max\" : 28.5,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 16.0,\n",
      "            \"upper_bound\" : 17.25,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 17.25,\n",
      "            \"upper_bound\" : 18.5,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 18.5,\n",
      "            \"upper_bound\" : 19.75,\n",
      "            \"count\" : 18.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 19.75,\n",
      "            \"upper_bound\" : 21.0,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 21.0,\n",
      "            \"upper_bound\" : 22.25,\n",
      "            \"count\" : 24.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 22.25,\n",
      "            \"upper_bound\" : 23.5,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 23.5,\n",
      "            \"upper_bound\" : 24.75,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 24.75,\n",
      "            \"upper_bound\" : 26.0,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 26.0,\n",
      "            \"upper_bound\" : 27.25,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 27.25,\n",
      "            \"upper_bound\" : 28.5,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 23.6, 18.5, 22.0, 20.7, 18.0, 18.0, 19.0, 21.5, 16.0, 18.5, 18.0, 17.5, 18.5, 21.0, 19.5, 20.5, 22.0, 19.0, 22.5, 19.0, 20.0, 19.5, 21.0, 20.0, 21.0, 22.5, 21.5, 20.8, 22.5, 16.0, 19.0, 20.0, 28.5, 26.5, 21.5, 21.0, 21.0, 21.5, 28.5, 24.5, 22.0, 18.0, 20.0, 24.0, 21.5, 17.5, 18.5, 21.0, 25.0, 19.5, 24.0, 21.0, 20.0, 23.5, 20.0, 18.5, 21.0, 20.0, 21.5, 21.5, 21.5, 24.0, 22.0, 25.5, 18.5, 20.0, 22.0, 19.5, 27.0, 25.0, 22.5, 21.0, 20.0, 22.0, 18.5, 22.0, 22.5, 23.0, 19.5, 24.5, 25.0, 19.0, 19.5, 20.0, 20.5, 23.0, 20.0, 20.0, 24.5 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c5\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 96.10112359550561,\n",
      "      \"sum\" : 8553.0,\n",
      "      \"std_dev\" : 13.731817349728228,\n",
      "      \"min\" : 70.0,\n",
      "      \"max\" : 162.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 70.0,\n",
      "            \"upper_bound\" : 79.2,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 79.2,\n",
      "            \"upper_bound\" : 88.4,\n",
      "            \"count\" : 33.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 88.4,\n",
      "            \"upper_bound\" : 97.6,\n",
      "            \"count\" : 23.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 97.6,\n",
      "            \"upper_bound\" : 106.8,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 106.8,\n",
      "            \"upper_bound\" : 116.0,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 116.0,\n",
      "            \"upper_bound\" : 125.2,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 125.2,\n",
      "            \"upper_bound\" : 134.4,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 134.4,\n",
      "            \"upper_bound\" : 143.6,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 143.6,\n",
      "            \"upper_bound\" : 152.8,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 152.8,\n",
      "            \"upper_bound\" : 162.0,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 70.0, 81.0, 86.0, 80.0, 88.0, 98.0, 162.0, 134.0, 85.0, 88.0, 88.0, 97.0, 88.0, 98.0, 86.0, 85.0, 90.0, 80.0, 84.0, 92.0, 94.0, 107.0, 88.0, 103.0, 88.0, 84.0, 85.0, 86.0, 108.0, 80.0, 87.0, 96.0, 119.0, 102.0, 86.0, 82.0, 85.0, 86.0, 92.0, 88.0, 80.0, 122.0, 104.0, 98.0, 106.0, 85.0, 94.0, 89.0, 96.0, 88.0, 101.0, 96.0, 89.0, 97.0, 92.0, 112.0, 102.0, 80.0, 86.0, 92.0, 113.0, 123.0, 112.0, 116.0, 98.0, 103.0, 93.0, 89.0, 97.0, 98.0, 89.0, 88.0, 107.0, 106.0, 106.0, 90.0, 88.0, 111.0, 88.0, 105.0, 112.0, 96.0, 86.0, 91.0, 95.0, 102.0, 120.0, 120.0, 96.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c6\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.9616853932584277,\n",
      "      \"sum\" : 174.59000000000006,\n",
      "      \"std_dev\" : 0.5397923778036865,\n",
      "      \"min\" : 0.98,\n",
      "      \"max\" : 3.52,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.98,\n",
      "            \"upper_bound\" : 1.234,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.234,\n",
      "            \"upper_bound\" : 1.488,\n",
      "            \"count\" : 18.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.488,\n",
      "            \"upper_bound\" : 1.742,\n",
      "            \"count\" : 21.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.742,\n",
      "            \"upper_bound\" : 1.996,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.996,\n",
      "            \"upper_bound\" : 2.25,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.25,\n",
      "            \"upper_bound\" : 2.504,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.504,\n",
      "            \"upper_bound\" : 2.758,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.758,\n",
      "            \"upper_bound\" : 3.012,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.012,\n",
      "            \"upper_bound\" : 3.266,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.266,\n",
      "            \"upper_bound\" : 3.52,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 2.2, 1.6, 1.45, 1.38, 2.45, 3.02, 2.5, 1.6, 2.55, 3.52, 2.85, 2.23, 1.45, 2.56, 2.5, 2.2, 1.68, 1.65, 1.38, 2.36, 2.74, 3.18, 2.55, 1.75, 2.48, 2.56, 2.46, 1.98, 2.0, 1.63, 2.0, 2.9, 3.18, 2.2, 2.62, 2.86, 2.6, 2.74, 2.13, 2.22, 2.1, 1.51, 1.3, 1.15, 1.7, 2.0, 1.62, 1.38, 1.79, 1.62, 2.32, 1.54, 1.4, 1.55, 2.0, 1.38, 1.5, 0.98, 1.7, 1.93, 1.41, 1.4, 1.48, 2.2, 1.8, 1.48, 1.74, 1.8, 1.9, 2.8, 2.6, 2.3, 1.83, 1.65, 1.39, 1.35, 1.28, 1.7, 1.48, 1.55, 1.98, 1.25, 1.39, 1.68, 1.68, 1.8, 1.59, 1.65, 2.05 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c7\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.4377528089887643,\n",
      "      \"sum\" : 127.96000000000002,\n",
      "      \"std_dev\" : 0.8903663591484944,\n",
      "      \"min\" : 0.34,\n",
      "      \"max\" : 5.08,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.34,\n",
      "            \"upper_bound\" : 0.8140000000000001,\n",
      "            \"count\" : 32.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8140000000000001,\n",
      "            \"upper_bound\" : 1.288,\n",
      "            \"count\" : 15.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.288,\n",
      "            \"upper_bound\" : 1.7620000000000002,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.7620000000000002,\n",
      "            \"upper_bound\" : 2.236,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.236,\n",
      "            \"upper_bound\" : 2.71,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.71,\n",
      "            \"upper_bound\" : 3.184,\n",
      "            \"count\" : 5.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.184,\n",
      "            \"upper_bound\" : 3.658,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.658,\n",
      "            \"upper_bound\" : 4.132000000000001,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.132000000000001,\n",
      "            \"upper_bound\" : 4.606,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.606,\n",
      "            \"upper_bound\" : 5.08,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.59, 1.5, 1.25, 1.46, 2.25, 2.26, 2.27, 0.99, 2.5, 3.75, 2.99, 2.17, 1.36, 2.11, 1.64, 1.92, 1.84, 2.03, 1.76, 2.04, 2.92, 2.58, 2.27, 2.03, 2.01, 2.29, 2.17, 1.6, 2.09, 1.25, 1.64, 2.79, 5.08, 2.13, 2.65, 3.03, 2.65, 3.15, 2.24, 2.45, 1.75, 1.25, 1.22, 1.09, 1.2, 0.58, 0.66, 0.47, 0.6, 0.48, 0.6, 0.5, 0.5, 0.52, 0.8, 0.78, 0.55, 0.34, 0.65, 0.76, 1.39, 1.57, 1.36, 1.28, 0.83, 0.58, 0.63, 0.83, 0.58, 1.31, 1.1, 0.92, 0.56, 0.6, 0.7, 0.68, 0.47, 0.92, 0.66, 0.84, 0.96, 0.49, 0.51, 0.7, 0.61, 0.75, 0.69, 0.68, 0.76 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c8\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.4149438202247191,\n",
      "      \"sum\" : 36.93,\n",
      "      \"std_dev\" : 0.12531419923227424,\n",
      "      \"min\" : 0.14,\n",
      "      \"max\" : 0.66,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.14,\n",
      "            \"upper_bound\" : 0.192,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.192,\n",
      "            \"upper_bound\" : 0.24400000000000002,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.24400000000000002,\n",
      "            \"upper_bound\" : 0.29600000000000004,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.29600000000000004,\n",
      "            \"upper_bound\" : 0.34800000000000003,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.34800000000000003,\n",
      "            \"upper_bound\" : 0.4,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.4,\n",
      "            \"upper_bound\" : 0.452,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.452,\n",
      "            \"upper_bound\" : 0.504,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.504,\n",
      "            \"upper_bound\" : 0.556,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.556,\n",
      "            \"upper_bound\" : 0.608,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.608,\n",
      "            \"upper_bound\" : 0.66,\n",
      "            \"count\" : 6.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 0.42, 0.52, 0.5, 0.58, 0.25, 0.17, 0.32, 0.14, 0.29, 0.24, 0.45, 0.26, 0.29, 0.34, 0.37, 0.32, 0.66, 0.37, 0.48, 0.39, 0.29, 0.24, 0.26, 0.6, 0.42, 0.43, 0.52, 0.3, 0.34, 0.43, 0.37, 0.32, 0.47, 0.43, 0.3, 0.21, 0.37, 0.39, 0.58, 0.4, 0.42, 0.21, 0.24, 0.27, 0.17, 0.6, 0.63, 0.53, 0.63, 0.58, 0.53, 0.53, 0.37, 0.5, 0.47, 0.29, 0.43, 0.4, 0.47, 0.45, 0.34, 0.22, 0.24, 0.26, 0.61, 0.53, 0.61, 0.48, 0.63, 0.53, 0.52, 0.5, 0.5, 0.6, 0.4, 0.41, 0.52, 0.43, 0.4, 0.39, 0.27, 0.4, 0.48, 0.44, 0.52, 0.43, 0.43, 0.53, 0.56 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c9\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 1.429213483146067,\n",
      "      \"sum\" : 127.19999999999996,\n",
      "      \"std_dev\" : 0.5674706837334035,\n",
      "      \"min\" : 0.55,\n",
      "      \"max\" : 3.58,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.55,\n",
      "            \"upper_bound\" : 0.8530000000000001,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.8530000000000001,\n",
      "            \"upper_bound\" : 1.1560000000000001,\n",
      "            \"count\" : 19.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.1560000000000001,\n",
      "            \"upper_bound\" : 1.459,\n",
      "            \"count\" : 21.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.459,\n",
      "            \"upper_bound\" : 1.7620000000000002,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.7620000000000002,\n",
      "            \"upper_bound\" : 2.0650000000000004,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.0650000000000004,\n",
      "            \"upper_bound\" : 2.3680000000000003,\n",
      "            \"count\" : 2.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.3680000000000003,\n",
      "            \"upper_bound\" : 2.6710000000000003,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.6710000000000003,\n",
      "            \"upper_bound\" : 2.974,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.974,\n",
      "            \"upper_bound\" : 3.277,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.277,\n",
      "            \"upper_bound\" : 3.58,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.38, 1.64, 1.63, 1.62, 1.99, 1.35, 3.28, 1.56, 1.77, 1.95, 2.81, 1.4, 1.35, 1.31, 1.42, 1.48, 1.42, 1.63, 1.63, 2.08, 2.49, 3.58, 1.22, 1.05, 1.44, 1.04, 2.01, 1.53, 1.61, 0.83, 1.87, 1.83, 1.87, 1.71, 2.01, 2.91, 1.35, 1.77, 1.76, 1.9, 1.35, 0.94, 0.83, 0.83, 0.84, 1.25, 0.94, 0.8, 1.1, 0.88, 0.81, 0.75, 0.64, 0.55, 1.02, 1.14, 1.3, 0.68, 0.86, 1.25, 1.14, 1.25, 1.26, 1.56, 1.87, 1.4, 1.55, 1.56, 1.14, 2.7, 2.29, 1.04, 0.8, 0.96, 0.94, 1.03, 1.15, 1.46, 0.97, 1.54, 1.11, 0.73, 0.64, 1.24, 1.06, 1.41, 1.35, 1.46, 1.35 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c10\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 5.289101112359549,\n",
      "      \"sum\" : 470.72999899999985,\n",
      "      \"std_dev\" : 2.884347761583861,\n",
      "      \"min\" : 1.28,\n",
      "      \"max\" : 13.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.28,\n",
      "            \"upper_bound\" : 2.452,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.452,\n",
      "            \"upper_bound\" : 3.6240000000000006,\n",
      "            \"count\" : 24.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.6240000000000006,\n",
      "            \"upper_bound\" : 4.796,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 4.796,\n",
      "            \"upper_bound\" : 5.968000000000001,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 5.968000000000001,\n",
      "            \"upper_bound\" : 7.140000000000001,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 7.140000000000001,\n",
      "            \"upper_bound\" : 8.312000000000001,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 8.312000000000001,\n",
      "            \"upper_bound\" : 9.484,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 9.484,\n",
      "            \"upper_bound\" : 10.656,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 10.656,\n",
      "            \"upper_bound\" : 11.828,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 11.828,\n",
      "            \"upper_bound\" : 13.0,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.74, 2.4, 3.6, 3.05, 2.15, 3.25, 2.6, 2.5, 2.9, 4.5, 2.3, 3.3, 2.45, 2.8, 2.06, 2.94, 2.7, 3.4, 3.3, 2.7, 2.65, 2.9, 2.0, 3.8, 3.08, 2.9, 1.9, 1.95, 2.06, 3.4, 1.28, 3.25, 6.0, 2.08, 2.6, 2.8, 2.76, 3.94, 3.0, 2.12, 2.6, 4.1, 5.4, 5.7, 5.0, 5.45, 7.1, 3.85, 5.0, 5.7, 4.92, 4.6, 5.6, 4.35, 4.4, 8.21, 4.0, 4.9, 7.65, 8.42, 9.4, 8.6, 10.8, 7.1, 10.52, 7.6, 7.9, 9.01, 7.5, 13.0, 11.75, 7.65, 5.88, 5.58, 5.28, 9.58, 6.62, 10.68, 10.26, 8.66, 8.5, 5.5, 9.899999, 9.7, 7.7, 7.3, 10.2, 9.3, 9.2 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c11\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 0.8233707865168536,\n",
      "      \"sum\" : 73.27999999999997,\n",
      "      \"std_dev\" : 0.21912975900457662,\n",
      "      \"min\" : 0.48,\n",
      "      \"max\" : 1.71,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 0.48,\n",
      "            \"upper_bound\" : 0.603,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.603,\n",
      "            \"upper_bound\" : 0.726,\n",
      "            \"count\" : 16.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.726,\n",
      "            \"upper_bound\" : 0.849,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.849,\n",
      "            \"upper_bound\" : 0.972,\n",
      "            \"count\" : 22.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 0.972,\n",
      "            \"upper_bound\" : 1.095,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.095,\n",
      "            \"upper_bound\" : 1.218,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.218,\n",
      "            \"upper_bound\" : 1.341,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.341,\n",
      "            \"upper_bound\" : 1.464,\n",
      "            \"count\" : 1.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.464,\n",
      "            \"upper_bound\" : 1.587,\n",
      "            \"count\" : 0.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.587,\n",
      "            \"upper_bound\" : 1.71,\n",
      "            \"count\" : 1.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 1.07, 1.08, 1.05, 0.96, 1.15, 1.16, 1.16, 0.95, 1.23, 1.04, 1.42, 1.27, 1.04, 0.8, 0.94, 1.04, 0.86, 1.0, 0.88, 0.86, 0.96, 0.75, 0.9, 1.23, 1.1, 0.93, 1.71, 0.95, 1.06, 0.7, 0.93, 0.8, 0.93, 0.92, 0.73, 0.75, 0.86, 0.69, 0.97, 0.89, 0.79, 0.76, 0.74, 0.66, 0.78, 0.75, 0.73, 0.75, 0.82, 0.81, 0.89, 0.77, 0.7, 0.89, 0.91, 0.65, 0.6, 0.58, 0.54, 0.55, 0.57, 0.59, 0.48, 0.61, 0.56, 0.58, 0.6, 0.57, 0.67, 0.57, 0.57, 0.56, 0.96, 0.87, 0.68, 0.7, 0.78, 0.85, 0.72, 0.74, 0.67, 0.66, 0.57, 0.62, 0.64, 0.7, 0.59, 0.6, 0.61 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c12\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 2.242134831460676,\n",
      "      \"sum\" : 199.55000000000015,\n",
      "      \"std_dev\" : 0.6941367153330001,\n",
      "      \"min\" : 1.27,\n",
      "      \"max\" : 3.69,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 1.27,\n",
      "            \"upper_bound\" : 1.512,\n",
      "            \"count\" : 13.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.512,\n",
      "            \"upper_bound\" : 1.754,\n",
      "            \"count\" : 20.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.754,\n",
      "            \"upper_bound\" : 1.996,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 1.996,\n",
      "            \"upper_bound\" : 2.238,\n",
      "            \"count\" : 7.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.238,\n",
      "            \"upper_bound\" : 2.48,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.48,\n",
      "            \"upper_bound\" : 2.722,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.722,\n",
      "            \"upper_bound\" : 2.9639999999999995,\n",
      "            \"count\" : 12.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 2.9639999999999995,\n",
      "            \"upper_bound\" : 3.206,\n",
      "            \"count\" : 6.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.206,\n",
      "            \"upper_bound\" : 3.448,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 3.448,\n",
      "            \"upper_bound\" : 3.69,\n",
      "            \"count\" : 3.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 3.21, 2.27, 2.65, 2.06, 3.3, 2.96, 2.63, 2.26, 2.74, 2.77, 2.83, 2.96, 2.77, 3.38, 2.44, 3.57, 3.3, 3.17, 2.42, 3.02, 3.26, 2.81, 2.78, 2.5, 2.31, 3.19, 2.87, 3.33, 2.96, 2.12, 3.05, 3.39, 3.69, 3.12, 3.1, 3.64, 3.28, 2.84, 2.44, 2.78, 2.57, 1.29, 1.42, 1.36, 1.29, 1.51, 1.58, 1.27, 1.69, 1.82, 2.15, 2.31, 2.47, 2.06, 2.05, 2.0, 1.68, 1.33, 1.86, 1.62, 1.33, 1.3, 1.47, 1.33, 1.51, 1.55, 1.48, 1.64, 1.73, 1.96, 1.78, 1.58, 1.82, 2.11, 1.75, 1.68, 1.75, 1.56, 1.75, 1.8, 1.92, 1.83, 1.63, 1.71, 1.74, 1.56, 1.56, 1.62, 1.6 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"_c13\",\n",
      "    \"inferred_type\" : \"Fractional\",\n",
      "    \"numerical_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 89,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"mean\" : 560.7528089887641,\n",
      "      \"sum\" : 49907.0,\n",
      "      \"std_dev\" : 145.24657693070466,\n",
      "      \"min\" : 290.0,\n",
      "      \"max\" : 937.0,\n",
      "      \"distribution\" : {\n",
      "        \"kll\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"lower_bound\" : 290.0,\n",
      "            \"upper_bound\" : 354.7,\n",
      "            \"count\" : 8.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 354.7,\n",
      "            \"upper_bound\" : 419.4,\n",
      "            \"count\" : 10.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 419.4,\n",
      "            \"upper_bound\" : 484.1,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 484.1,\n",
      "            \"upper_bound\" : 548.8,\n",
      "            \"count\" : 11.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 548.8,\n",
      "            \"upper_bound\" : 613.5,\n",
      "            \"count\" : 14.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 613.5,\n",
      "            \"upper_bound\" : 678.2,\n",
      "            \"count\" : 17.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 678.2,\n",
      "            \"upper_bound\" : 742.9,\n",
      "            \"count\" : 9.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 742.9,\n",
      "            \"upper_bound\" : 807.6,\n",
      "            \"count\" : 3.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 807.6,\n",
      "            \"upper_bound\" : 872.3,\n",
      "            \"count\" : 4.0\n",
      "          }, {\n",
      "            \"lower_bound\" : 872.3,\n",
      "            \"upper_bound\" : 937.0,\n",
      "            \"count\" : 2.0\n",
      "          } ],\n",
      "          \"sketch\" : {\n",
      "            \"parameters\" : {\n",
      "              \"c\" : 0.64,\n",
      "              \"k\" : 2048.0\n",
      "            },\n",
      "            \"data\" : [ [ 625.0, 480.0, 450.0, 495.0, 290.0, 345.0, 937.0, 625.0, 428.0, 660.0, 406.0, 710.0, 562.0, 438.0, 415.0, 672.0, 315.0, 510.0, 488.0, 312.0, 680.0, 562.0, 325.0, 607.0, 434.0, 385.0, 407.0, 495.0, 345.0, 372.0, 564.0, 625.0, 465.0, 365.0, 380.0, 380.0, 378.0, 352.0, 466.0, 342.0, 580.0, 630.0, 530.0, 560.0, 600.0, 650.0, 695.0, 720.0, 515.0, 580.0, 590.0, 600.0, 780.0, 520.0, 550.0, 855.0, 830.0, 415.0, 625.0, 650.0, 550.0, 500.0, 480.0, 425.0, 675.0, 640.0, 725.0, 480.0, 880.0, 660.0, 620.0, 520.0, 680.0, 570.0, 675.0, 615.0, 520.0, 695.0, 685.0, 750.0, 630.0, 510.0, 470.0, 660.0, 740.0, 750.0, 835.0, 840.0, 560.0 ] ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  } ]\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  FileUtil:29 - Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  YarnClientSchedulerBackend:54 - Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  YarnClientSchedulerBackend:54 - Shutting down all executors\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices\u001b[0m\n",
      "\u001b[34m(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  YarnClientSchedulerBackend:54 - Stopped\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  MemoryStore:54 - MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  BlockManager:54 - BlockManager stopped\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  SparkContext:54 - Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  Main:65 - Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  Main:141 - Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  ShutdownHookManager:54 - Shutdown hook called\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-21763661-f33b-4da7-972f-90bd3e546864\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-4ead64d5-a221-43c8-b0a4-efd0d03d9f33\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57,657 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2022-01-14 12:58:57,658 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7fbb48dff438>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_monitor.suggest_baseline(\n",
    "    baseline_dataset=f's3://{bucket}/data/train.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, provide the monitoring schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: wine-monitoring-schedule\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "my_monitor.delete_monitoring_schedule()\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "my_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name='wine-monitoring-schedule',\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    statistics=my_monitor.baseline_statistics(),\n",
    "    constraints=my_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you configured Model Monitor to watch a simple model. Next, we'll monitor the same deployment for explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. If you aren't going to follow up with the Clarify exercise within a few hours, use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: wine-monitoring-schedule\n"
     ]
    }
   ],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarify\n",
    "\n",
    "For the last exercise we'll deploy an explainability monitor using Clarify. We're going to use the model that you deployed in the last exercise, but if you cleaned up your deployments from the previous exercise, that's ok! You can rerun the deployment from the previous exercise up to the point where we deployed our model. It'll look like this:\n",
    "\n",
    "```python\n",
    "xgb_predictor = model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m4.xlarge',\n",
    "    data_capture_config=data_capture_config\n",
    ")\n",
    "```\n",
    "\n",
    "Once your model is deployed, you can come back here. _REMINDER_: you need to clean up your deployment, don't leave it running overnight. We'll provide some code at the end to delete your deployment.\n",
    "\n",
    "## Prep\n",
    "\n",
    "We'll begin by reloading our data from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data['data'])\n",
    "df.columns = data['feature_names']\n",
    "df.rename(columns = {'od280/od315_of_diluted_wines':'od280_od315_of_diluted_wines'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to put the target variable in the first column per the docs for our chosen algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = data['target']\n",
    "df.set_index(df.pop('TARGET'), inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the data to S3 as train and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = int(len(df)/2)\n",
    "train, test = df.iloc[delimiter:], df.iloc[:delimiter]\n",
    "\n",
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "test.to_csv(\"validation.csv\", header=False, index=False)\n",
    "\n",
    "val_location = session.upload_data('./validation.csv', key_prefix=\"data\")\n",
    "train_location = session.upload_data('./train.csv', key_prefix=\"data\")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our data is staged and our model is deployed - let's monitor it for explainability. We need to define three config objects, the `SHAPConfig`, the `ModelConfig`, and the `ExplainabilityAnalysisConfig`. Below, we provide the `SHAPConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[train.mean().astype(int).to_list()[1:]],\n",
    "    num_samples=int(train.size),\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, fill in the blanks to define the `ModelConfig` and `ExplainabilityAnalysisConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=xgb_predictor.endpoint_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    content_type=\"text/csv\",\n",
    "    accept_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "analysis_config = sagemaker.model_monitor.ExplainabilityAnalysisConfig(\n",
    "        explainability_config=shap_config,\n",
    "        model_config=model_config,\n",
    "        headers=train.columns.to_list()[1:],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply our config, we need to create the monitor object. This is what we'll apply all our config to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor = sagemaker.model_monitor.ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything's ready! Below, create a monitoring schedule using the configs we created. Set the schedule to run _daily_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "\n",
    "explainability_uri = f\"s3://{bucket}/model_explainability\"\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=explainability_uri,\n",
    "    analysis_config=analysis_config,\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way to go! You can check that your schedule was created by selecting the `SageMaker components and registries` tab on the far left.\n",
    "\n",
    "In this exercise you deployed a monitor for explainability to your SageMaker endpoint. This is the last exercise - you'll apply these learnings again in your Project at the end of the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REMINDER:__ Don't leave your model deployed overnight. Use the code below to remove your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2021-09-13-17-25-08-560\n",
      "\n",
      "Deleting Monitoring Schedule with name: wine-monitoring-schedule\n"
     ]
    }
   ],
   "source": [
    "monitors = xgb_predictor.list_monitors()\n",
    "for monitor in monitors:\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
